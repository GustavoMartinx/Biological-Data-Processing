{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação do dataset\n",
    "\n",
    "Neste _notebook_ é realizada a trasnformação do _dataset_ EEG de `.txt` para um arquivo `.npy` (_numpy array_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-126218.33398561 -126043.45393699 -110719.61202855 ...  -88472.92077219\n",
      "  -134513.66985007   50744.94191944]\n",
      " [-126312.74775419 -126165.36035125 -110842.12193991 ...  -88588.63575323\n",
      "  -134644.85223828   50636.84888325]\n",
      " [-126265.65262862 -126098.03689695 -110748.62459286 ...  -88518.27246169\n",
      "  -134581.84267066   50720.93614589]\n",
      " ...\n",
      " [-126817.22662654 -126105.99411797 -110607.13805045 ...  -88017.30281321\n",
      "  -134783.07542599   49024.5728522 ]\n",
      " [-126756.1169572  -126082.54713804 -110599.27023641 ...  -87981.74118778\n",
      "  -134691.94736385   49057.2511026 ]\n",
      " [-126846.86503969 -126213.81893323 -110774.10558153 ...  -88127.02752674\n",
      "  -134776.66047533   48915.69750496]]\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Automatizar a obtenção dos dados do dataset\n",
    "\n",
    "directory = '../dataset-s6/'\n",
    "\n",
    "# Get list of files in directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Filter files that are txt and start with 'OpenBCI...'\n",
    "dataset_files = [file for file in files if file.endswith('.txt') and file.startswith('OpenBCI')]\n",
    "\n",
    "# Load data from each file into an array\n",
    "data_array = []\n",
    "for file in dataset_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    data = np.loadtxt(file_path, dtype=float, delimiter=',', skiprows=5, usecols=range(1, 9))\n",
    "    data_array.append(data)\n",
    "\n",
    "# Tarefa 1: Cortar os dados ruidosos de cada file (posição) do data_array\n",
    "\n",
    "# ---------------------- TO DO: excluir\n",
    "# filenames de exemplo\n",
    "file1 = '../dataset-s6/OpenBCI-RAW-2023-10-10_14-22-28.txt'\n",
    "file2 = '../dataset-s6/OpenBCI-RAW-2023-10-25_17-43-36.txt'\n",
    "file3 = '../dataset-s6/OpenBCI-RAW-2023-11-14_17-25-16.txt'\n",
    "\n",
    "# skiprows=5 pula 5 linhas | 8 eletrodos, então 8 colunas de dados usecols 1-8\n",
    "data1 = np.loadtxt(file1, dtype=float, delimiter=',', skiprows=5, usecols=range(1, 9))\n",
    "data2 = np.loadtxt(file2, dtype=float, delimiter=',', skiprows=5, usecols=range(1, 9))\n",
    "data3 = np.loadtxt(file3, dtype=float, delimiter=',', skiprows=5, usecols=range(1, 9))\n",
    "# ----------------------\n",
    "\n",
    "# Tarefa 2: Realizar os cortes de dados ruidosos\n",
    "# data1: 500 pois são 2 segundos iniciais jogados fora (2x250)\n",
    "# data2: o início foi cortado, bem como o fim (por isso os -1750)\n",
    "# data3: corte dos 2 segundos iniciais também\n",
    "\n",
    "# concatenar os vários arquivos .txts analisados em um único .npy array\n",
    "data_final = np.concatenate((data1[500:,:], data2[500:-1750,:], data3[500:,:]), axis=0)\n",
    "\n",
    "np.save('../dataset-s6/data.npy', data_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
