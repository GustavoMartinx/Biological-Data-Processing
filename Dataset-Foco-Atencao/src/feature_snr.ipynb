{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração da característica relação sinal-ruído (SNR) de dados de EEG\n",
    "\n",
    "O objetivo é utilizar um conjunto de dados com nível de atividade cerebral considerado basal e \"subtraí-lo\" do sinal obtido no experimento a fim de reconhecer os padrões de foco com maior clareza.\n",
    "\n",
    "No contexto da caracterização de foco, podemos, a partir do sinal basal, classificar os sinais dos ritmos cerebrais com a presença ou não de foco, de forma que as amostras de sinais extraídas de um buffer sejam rotuladas com com a presença ou não de foco.\n",
    "\n",
    "Esta análise será realizada com o auxílio do classificador SVM (_Support Vector Machine_). Nesse sentido, uma porcetagem das amostras são utilizadas para treino e outra para o teste (30 e 70% respectivamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform a string that represents a time value (\"min:sec\") into number and converts it to seconds\n",
    "def convert_min_to_sec(time):\n",
    "    minutes, seconds = map(int, time.split(\":\"))\n",
    "    return minutes * 60 + seconds\n",
    "\n",
    "# Transfor a string thats represents a range time \"0:21 - 0:40\" into index that will be used to cut data\n",
    "def convert_time_range_to_index(timerange):\n",
    "    start, end = map(str, timerange.split(\" - \"))\n",
    "    new_start = convert_min_to_sec(start)\n",
    "    new_end = convert_min_to_sec(end)\n",
    "    \n",
    "    index = []\n",
    "    index.append(new_start * 250)\n",
    "    index.append(new_end * 250)\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 8\n",
    "ch_types = ['eeg'] * n_channels\n",
    "sfreq = 250\n",
    "ch_names = [\"F3\", \"Fz\", \"F4\", \"C3\", \"Cz\", \"C4\", \"P3\", \"P4\"]\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "info.set_montage(\"standard_1020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia = '../dataset-s7/IA/OpenBCI-RAW-2023-09-28_16-51-25_IA.txt'\n",
    "ia_ob = np.loadtxt(ia, delimiter=',', skiprows=5, usecols=range(1, 9))\n",
    "\n",
    "basal = '../dataset-s7/TF/OpenBCI-RAW-2023-11-07_13-17-01_TF.txt'\n",
    "basal_ob = np.loadtxt(basal, delimiter=',', skiprows=5, usecols=range(1, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aula IA\n",
    "ia_timeranges = [\n",
    "    \"6:00 - 10:17\",\n",
    "]\n",
    "\n",
    "# Basal (TF)\n",
    "basal_timerange = [\n",
    "    \"3:28 - 4:28\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia_index = []\n",
    "ia_index = convert_time_range_to_index(ia_timeranges[1])\n",
    "\n",
    "basal_index = []\n",
    "basal_index = convert_time_range_to_index(basal_timerange[0])\n",
    "\n",
    "data_cut_ia = ia_ob[ia_index[0]:ia_index[1], :]\n",
    "data_cut_basal = basal_ob[basal_index[0]:basal_index[1], :]\n",
    "\n",
    "X = {\n",
    "    'ia': mne.io.RawArray(data_cut_ia.T, info),\n",
    "    'basal': mne.io.RawArray(data_cut_basal.T, info),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimando o ruído de fundo através do sinal basal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista que armazena as médias de potência para cada canal\n",
    "noise_power = []\n",
    "\n",
    "for channel_data in X['basal']: # precisa ser transposta? parece que ja ta transposta\n",
    "    fft_result = np.fft.fft(channel_data)\n",
    "\n",
    "    # densidade espectral de potência (PSD)\n",
    "    psd = np.abs(fft_result) ** 2\n",
    "    \n",
    "    # média da potência no intervalo de tempo sem estímulo\n",
    "    base_power = np.mean(psd)\n",
    "    noise_power.append(base_power)\n",
    "\n",
    "# média das médias de potência de todos os canais para estimar o ruído de fundo\n",
    "estimated_background_noise = np.mean(noise_power)\n",
    "print(estimated_background_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos calcular o SNR de \"banda estreita\". Pode ser observado pela seguinte equação:\n",
    "\n",
    "$SNR_{banda\\ estreita} = 10 \\cdot \\log_{10}\\left(\\frac{\\text{energia total do espectro}}{\\text{média das amplitudes nas frequências vizinhas}}\\right)$\n",
    "\n",
    "Já o SNR de banda larga é definido da seguinte forma:\n",
    "\n",
    "$SNR_{banda\\ larga} = 10 \\cdot \\log_{10}\\left(\\frac{\\text{energia total do espectro}}{\\text{energia total do espectro de amplitude}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora vamos adaptar ambas características \n",
    "# aplicando para o nosso sinal de interesse\n",
    "\n",
    "# forçando (estragando) valor de \"estimated_background_noise\" para não sobrar valores negativos\n",
    "target_amplitudes_adjusted = data_cut_ia - estimated_background_noise # data_cut_ia ou X['ia'] ?\n",
    "\n",
    "# subtraindo o ruído de fundo das amplitudes\n",
    "narrow_band_SNR = 10 * np.log10(target_amplitudes_adjusted / estimated_background_noise)\n",
    "print(narrow_band_SNR)\n",
    "print(narrow_band_SNR.shape)\n",
    "\n",
    "total_power = np.sum(target_amplitudes_adjusted)\n",
    "wide_band_SNR = 10 * np.log10(target_amplitudes_adjusted / total_power)\n",
    "print(wide_band_SNR)\n",
    "print(wide_band_SNR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa para aplicação das características SNR:\n",
    "\n",
    "Agora que temos os dois vetores de características SNR, podemos utilizar buffers com e sem a evocação dos rítmos que caracterizam o foco.\n",
    "\n",
    "#### Divisão dos dados\n",
    "\n",
    "Utilizando a iteração (por exemplo, de 5 segundos caracterizada pela janela) realizada no sinal a cada ~1 segundo, realize a rotulação dos dados de interesse (Beta e Gamma). Ou seja, cada amostra sera um sinal de 5 segundos (1250 pontos de 8 canais). A janela que não for qualificada como Beta ou Gama por exemplo, poderá ser rotulada com \"desfoque\". Se acharem interessante, adicionar rótulos do ritmo Theta também.\n",
    "\n",
    "No caso do sinal que representa o basal (se tiverem) poderá pegar um único sinal de aproximadamente 30 segundos para ser utilizado na equação de ruído, que irá ter como resultado um único valor. Lembrando que o valor de ruído deve atuar no sinal no domínio da frequência.\n",
    "\n",
    "#### Classificação\n",
    "\n",
    "Em nossos dados simulados, temos 150.000 pontos com 8 canais. A utilização desses dados funcionará da seguinte forma para a criação do vetor de características:\n",
    "\n",
    "- 150.000 (pontos totais) / 250 (taxa de amostragem) = 600 segundos\n",
    "- 600 / 5 (tamanho da janela sem sobreposição) = 120 amostras\n",
    "\n",
    "| 1   | SNRw1                | SNRw2 | ... | SNRw8 | SNRn1 | SNRn2 | ... | SNRn8 |\n",
    "|-----|----------------------|-------|-----|-------|-------|-------|-----|-------|\n",
    "| 2   | [w1, w2, ..., w1250] |       |     |       |       |       |     |       |\n",
    "| 3   |                      |       |     |       |       |       |     |       |\n",
    "| ... |                      |       |     |       |       |       |     |       |\n",
    "| 120 |                      |       |     |       |       |       |     |       |\n",
    "\n",
    "- Agora transforme cada um dos vetores de pontos no domínio da frequência (1250 pontos) em um único valor real. Neste caso pode ser utilizado tanto a média como a mediana (ou ambos). Se utilizarmos as duas, teremos no final 32 colunas de características:\n",
    "    - 8 canais\n",
    "    - SNR narrow e SNR wide (2)\n",
    "    - Média e mediana (2)\n",
    "\n",
    "| 1   | 1   | ... | 32 |\n",
    "|-----|-----|-----|----|\n",
    "| 2   | w'  | ... |    |\n",
    "| 3   | ... |     |    |\n",
    "| ... |     |     |    |\n",
    "| 120 |     |     |    |\n",
    "\n",
    "\n",
    "\n",
    "Após obter o vetor de característica, realizar a divisão dos dados em treinamento e teste (normalmente uma proporção de 70 e 30% respectivamente) e aplicar para o classificador SVM.\n",
    "\n",
    "**PLUS**: Ao final da tarefa, verificar a melhora dos resultados utilizando um seletor de características. Neste caso, podemos utilizar o RFE (*Recursive Feature Elimination*) em uma fase anterior a classificação para reduzir as 32 características se for necessário.\n",
    "\n",
    "----\n",
    "\n",
    "### Dúvidas\n",
    "\n",
    "1 - `for channel_data in X['basal']: # precisa ser transposta? parece que ja ta transposta`\n",
    "2 - `target_amplitudes_adjusted = data_cut_ia - estimated_background_noise # data_cut_ia ou X['ia'] ?`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
